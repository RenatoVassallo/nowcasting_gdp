{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Random Forest Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from config.paths import dir_input_raw, dir_input_cleaned\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function, generate lagged datasets for testing on vintages\n",
    "def gen_lagged_data(metadata, data, last_date, lag):\n",
    "    # only go up to the last date\n",
    "    lagged_data = data.loc[data.date <= last_date, :].reset_index(drop=True)\n",
    "    for col in lagged_data.columns[1:]:\n",
    "        pub_lag = metadata.loc[metadata.series == col, \"months_lag\"].values[0] # publication lag of this particular variable\n",
    "        # go back as far as needed for the pub_lag of the variable, then + the lag (so -2 for 2 months back), also -1 because 0 lag means in month, last month data available, not current month in\n",
    "        lagged_data.loc[(len(lagged_data) - pub_lag + lag - 1) :, col] = np.nan\n",
    "\n",
    "    return lagged_data\n",
    "\n",
    "# helper function, flatten a dataset for methods that don't do timeseries, extra columns for each lag\n",
    "def flatten_data(data, target_variable, n_lags):\n",
    "    flattened_data = data.loc[~pd.isna(data[target_variable]), :]\n",
    "    orig_index = flattened_data.index\n",
    "    for i in range(1, n_lags + 1):\n",
    "        lagged_indices = orig_index - i\n",
    "        lagged_indices = lagged_indices[lagged_indices >= 0]\n",
    "        tmp = data.loc[lagged_indices, :]\n",
    "        tmp.date = tmp.date + pd.DateOffset(months=i)\n",
    "        tmp = tmp.drop([target_variable], axis=1)\n",
    "        tmp.columns = [j + \"_\" + str(i) if j != \"date\" else j for j in tmp.columns]\n",
    "        flattened_data = flattened_data.merge(tmp, how=\"left\", on=\"date\")\n",
    "\n",
    "    return flattened_data\n",
    "\n",
    "# helper function fill missings in a dataset with the mean from the training set\n",
    "def mean_fill_dataset(training, test):\n",
    "    mean_dict = {}\n",
    "    for col in training.columns[1:]:\n",
    "        mean_dict[col] = np.nanmean(training[col])\n",
    "    filled = test.copy()\n",
    "    for col in training.columns[1:]:\n",
    "        filled.loc[pd.isna(filled[col]), col] = mean_dict[col]\n",
    "    return filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "# ==============================================================================\n",
    "target = \"gdpc1\"\n",
    "gdp_lag = 1\n",
    "lags_to_test = list(range(-2, 3))  # Lags of -2, -1, 0, 1, 2 months\n",
    "start_train = \"1947-01-01\" \n",
    "start_val   = \"2005-03-01\"\n",
    "start_test  = \"2010-04-01\"\n",
    "\n",
    "# Data read and preprocessing\n",
    "# ==============================================================================\n",
    "metadata = pd.read_csv(os.path.join(dir_input_raw, \"meta_data.csv\"))\n",
    "data     = pd.read_csv(os.path.join(dir_input_cleaned, \"data_tf.csv\"), parse_dates=[\"date\"])\n",
    "data     = data.set_index(\"date\").asfreq(\"MS\")\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "data_train = data[start_train: \"2005-02-01\"]\n",
    "data_val   = data[start_val: \"2010-03-01\"]\n",
    "data_test  = data[start_test:]\n",
    "\n",
    "# Plot training, validation, and test data\n",
    "# ==============================================================================\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data_train[target].dropna(),label=\"Training\")\n",
    "plt.plot(data_val[target].dropna(),label=\"Validation\")\n",
    "plt.title('GDP growth for different sets', fontsize=16)\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.ylabel('GDP Growth', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the model\n",
    "\n",
    "The model is trained on a rolling basis. So if we are predicting 2000-03-01, the model is trained on data as it would have appeared in 1999-12-01, right before the beginning of the prediction period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_val = pd.concat([data_train, data_val])     # Monthly data for training and validation\n",
    "data_train_val.reset_index(inplace=True)\n",
    "data_train_val.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is form information only. The process is repeated below for each test date.\n",
    "transformed_train = mean_fill_dataset(data_train_val, data_train_val) # fill any missing values with the mean\n",
    "transformed_train = flatten_data(transformed_train, target, 4) # 4 means include 4 additional lags of each variable\n",
    "# only keep quarterly observations and drop early observations with not enough history for lagged variables\n",
    "transformed_train = transformed_train.loc[transformed_train.date.dt.month.isin([3,6,9,12]),:].dropna(axis=0, how=\"any\").reset_index(drop=True)\n",
    "\n",
    "# we can see that e.g. the variable `payems` now has 4 columns in the data, for each of the lags, and that the data now has one row per quarter\n",
    "transformed_train.loc[:, [True] + list(transformed_train.columns[1:].str.contains(\"payems\"))].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rolling nowcast on artificial data vintages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates and actual values for validation\n",
    "# ==============================================================================\n",
    "dates         = data_val.dropna().index.strftime(\"%Y-%m-%d\").to_list()  # Quarterly dates\n",
    "actual_values = data_val[target].dropna().values                        # Quarterly GDP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {k: [] for k in lags_to_test}\n",
    "for date in dates:\n",
    "    # preparing the data for the model\n",
    "    train = data_train_val.loc[data_train_val.date <= str(pd.to_datetime(date) - pd.tseries.offsets.DateOffset(months=3))[:10],:] # data as it would have appeared at beginning of prediction period\n",
    "    transformed_train = mean_fill_dataset(train, train) # fill any missing values with the mean\n",
    "    transformed_train = flatten_data(transformed_train, target, 4) # 4 means include 4 additional lags of each variable\n",
    "    # only keep quarterly observations and drop early observations with not enough history for lagged variables\n",
    "    transformed_train = transformed_train.loc[transformed_train.date.dt.month.isin([3,6,9,12]),:].dropna(axis=0, how=\"any\").reset_index(drop=True)\n",
    "    \n",
    "    # train 10 models to average outputs because of stochasticity\n",
    "    models = []\n",
    "    for i in range(10):\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators = 100, \n",
    "            criterion = \"squared_error\", \n",
    "            max_depth = None, \n",
    "            min_samples_split = 0.01, \n",
    "            min_samples_leaf = 0.01,\n",
    "            max_features = \"sqrt\",\n",
    "            bootstrap = False\n",
    "        )\n",
    "\n",
    "        x = transformed_train.drop([\"date\", target], axis=1)\n",
    "        y = transformed_train[target]\n",
    "\n",
    "        # fitting the actual models\n",
    "        model.fit(x, y)\n",
    "        models.append(model)\n",
    "\n",
    "    for lag in lags_to_test:\n",
    "        # the data available for this date at this artificial vintage\n",
    "        tmp_data = gen_lagged_data(metadata, data_train_val, date, lag)\n",
    "        # get data in format necessary for model\n",
    "        tmp_data = mean_fill_dataset(train, tmp_data) # fill with the mean of the training set\n",
    "        tmp_data = flatten_data(tmp_data, target, 4)\n",
    "        x = tmp_data.loc[tmp_data.date == date, :].drop([\"date\", target], axis=1)\n",
    "        # average results of 10 models' predictions\n",
    "        preds = []\n",
    "        for i in range(10):\n",
    "            prediction = models[i].predict(x)[0]\n",
    "            preds.append(prediction)\n",
    "        \n",
    "        pred_dict[lag].append(np.nanmean(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(pred_dict)\n",
    "final_df[\"Actual GDP Growth\"] = actual_values\n",
    "final_df = final_df[[\"Actual GDP Growth\", -2, -1, 0, 1, 2]]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Assess and visualize model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table of RMSE by vintage\n",
    "performance = pd.DataFrame(columns=[\"Vintage\", \"RMSE\"])\n",
    "for lag in lags_to_test:\n",
    "    tmp = pd.DataFrame({\n",
    "        \"Vintage\":lag,\n",
    "        \"RMSE\":np.sqrt(np.mean((np.array(actual_values) - np.array(pred_dict[lag])) ** 2))\n",
    "    }, index=[0])\n",
    "    performance = pd.concat([performance, tmp]).reset_index(drop=True)\n",
    "performance.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot each lag series using a loop\n",
    "for label in final_df.columns:\n",
    "    linestyle = '-' if label == \"Actual GDP Growth\" else '--'  # Solid line for actual, dashed for lags\n",
    "    plt.plot(data_val.dropna().index, final_df[label], label=label, marker='o', markersize=10 ,linestyle=linestyle, linewidth=3)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Predictions vs Actual GDP', fontsize=16)\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.ylabel('GDP Growth', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
